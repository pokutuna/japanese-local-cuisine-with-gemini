from _typeshed import Incomplete
from scrapy import Spider as Spider
from scrapy.crawler import Crawler as Crawler
from typing import Any, Dict, Optional

logger: Incomplete
StatsT = Dict[str, Any]

class StatsCollector:
    def __init__(self, crawler: Crawler) -> None: ...
    def get_value(self, key: str, default: Any = None, spider: Optional[Spider] = None) -> Any: ...
    def get_stats(self, spider: Optional[Spider] = None) -> StatsT: ...
    def set_value(self, key: str, value: Any, spider: Optional[Spider] = None) -> None: ...
    def set_stats(self, stats: StatsT, spider: Optional[Spider] = None) -> None: ...
    def inc_value(self, key: str, count: int = 1, start: int = 0, spider: Optional[Spider] = None) -> None: ...
    def max_value(self, key: str, value: Any, spider: Optional[Spider] = None) -> None: ...
    def min_value(self, key: str, value: Any, spider: Optional[Spider] = None) -> None: ...
    def clear_stats(self, spider: Optional[Spider] = None) -> None: ...
    def open_spider(self, spider: Spider) -> None: ...
    def close_spider(self, spider: Spider, reason: str) -> None: ...

class MemoryStatsCollector(StatsCollector):
    spider_stats: Incomplete
    def __init__(self, crawler: Crawler) -> None: ...

class DummyStatsCollector(StatsCollector):
    def get_value(self, key: str, default: Any = None, spider: Optional[Spider] = None) -> Any: ...
    def set_value(self, key: str, value: Any, spider: Optional[Spider] = None) -> None: ...
    def set_stats(self, stats: StatsT, spider: Optional[Spider] = None) -> None: ...
    def inc_value(self, key: str, count: int = 1, start: int = 0, spider: Optional[Spider] = None) -> None: ...
    def max_value(self, key: str, value: Any, spider: Optional[Spider] = None) -> None: ...
    def min_value(self, key: str, value: Any, spider: Optional[Spider] = None) -> None: ...
