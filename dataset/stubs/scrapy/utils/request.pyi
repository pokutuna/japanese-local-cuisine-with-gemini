from scrapy import Request as Request, Spider as Spider
from scrapy.crawler import Crawler as Crawler
from scrapy.exceptions import ScrapyDeprecationWarning as ScrapyDeprecationWarning
from scrapy.utils.httpobj import urlparse_cached as urlparse_cached
from scrapy.utils.misc import load_object as load_object
from scrapy.utils.python import to_bytes as to_bytes, to_unicode as to_unicode
from typing import Iterable, Optional, Protocol, Union

def request_fingerprint(request: Request, include_headers: Optional[Iterable[Union[bytes, str]]] = None, keep_fragments: bool = False) -> str: ...
def fingerprint(request: Request, *, include_headers: Optional[Iterable[Union[bytes, str]]] = None, keep_fragments: bool = False) -> bytes: ...

class RequestFingerprinterProtocol(Protocol):
    def fingerprint(self, request: Request) -> bytes: ...

class RequestFingerprinter:
    @classmethod
    def from_crawler(cls, crawler): ...
    def __init__(self, crawler: Optional['Crawler'] = None) -> None: ...
    def fingerprint(self, request: Request) -> bytes: ...

def request_authenticate(request: Request, username: str, password: str) -> None: ...
def request_httprepr(request: Request) -> bytes: ...
def referer_str(request: Request) -> Optional[str]: ...
def request_from_dict(d: dict, *, spider: Optional[Spider] = None) -> Request: ...
def request_to_curl(request: Request) -> str: ...
